{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a8bfee6-3bc9-487b-91a3-1b3d6ef23c0b",
   "metadata": {},
   "source": [
    "### Step 1: Import necessary libraries \n",
    "\n",
    "Before you start, you need to import the required libraries: TensorFlow and Keras. Keras is included within TensorFlow as `tensorflow.keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0411f195-4fc9-4a1e-9878-ad68ceb49fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\programdata\\miniconda3\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: pyarrow in c:\\programdata\\miniconda3\\lib\\site-packages (19.0.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\programdata\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.12.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\programdata\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\programdata\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\programdata\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.64.3)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\programdata\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in c:\\programdata\\miniconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\programdata\\miniconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\programdata\\miniconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\miniconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in c:\\programdata\\miniconda3\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\programdata\\miniconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\miniconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\miniconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\miniconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\programdata\\miniconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from scikit-learn) (1.15.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\miniconda3\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\miniconda3\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from matplotlib) (4.55.6)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\programdata\\miniconda3\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\programdata\\miniconda3\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\miniconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\miniconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: requests in c:\\programdata\\miniconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\miniconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\miniconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\miniconda3\\lib\\site-packages (from requests) (2023.11.17)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow pyarrow \n",
    "%pip install pandas  \n",
    "%pip install scikit-learn \n",
    "%pip install matplotlib \n",
    "%pip install requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "969d9c46-25fe-4dc3-9105-e503b2d94b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import requests\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b13adec-734a-40bc-a58c-7a56619e9349",
   "metadata": {},
   "source": [
    "####  Setup the Environment to generate synthetic stock price data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5f05cf8e-6395-476e-b3b7-a5b3c094d084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic stock_prices.csv created and loaded.\n"
     ]
    }
   ],
   "source": [
    "# create a synthatic stock price dataset\n",
    "np.random.seed(42)\n",
    "data_length = 2000 \n",
    "trend = np.linspace(100, 200, data_length)\n",
    "noise = np.random.normal(0, 2, data_length)\n",
    "synthatic_data = trend + noise\n",
    "\n",
    "# Create dataframe and save it as stock_prices.csv\n",
    "data = pd.DataFrame(synthatic_data, columns = [\"close\"])\n",
    "data.to_csv(\"stock_prices.csv\", index=False)\n",
    "print(\"Synthetic stock_prices.csv created and loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "357b34e0-be51-44cf-b745-f2346e8ba8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (1899, 100, 1)\n",
      "Shape of Y: (1899,)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv(\"stock_prices.csv\")\n",
    "data = data[[\"close\"]].values\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "# prepare the data for training\n",
    "def create_dataset(data, time_step = 1):\n",
    "    x, y = [],[]\n",
    "\n",
    "    for i in range(len(data)-time_step-1):\n",
    "        a = data[i:(i + time_step), 0]\n",
    "        x.append(a)\n",
    "        y.append(data[i + time_step, 0])\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "time_step = 100\n",
    "x, y = create_dataset(data, time_step)\n",
    "x = x.reshape(x.shape[0], x.shape[1], 1)\n",
    "\n",
    "print(\"Shape of X:\", x.shape) \n",
    "print(\"Shape of Y:\", y.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2719c2ac-7731-4c2a-8b42-acc7cb1f409f",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "`tensorflow` is the main library for machine learning in Python.  \n",
    "\n",
    "`stock_prices.csv` is the data set that is loaded. \n",
    "\n",
    "`MinMaxScaler` method is used to normalize the data.  \n",
    "\n",
    "`create_dataset`method is used to prepare the data for training. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fe1967-4c29-4b3b-92ff-c783e9106fde",
   "metadata": {},
   "source": [
    "### Step 2: Implement Multi-Head Self-Attention \n",
    "\n",
    "Define the Multi-Head Self-Attention mechanism. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "14a08673-c834-4f61-bfa4-f0ec1acd3a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(Layer):\n",
    "    def __init__(self, embed_dim, num_heads=8):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.projection_dim = embed_dim // num_heads\n",
    "        self.query_dense = Dense(embed_dim)\n",
    "        self.key_dense = Dense(embed_dim)\n",
    "        self.value_dense = Dense(embed_dim)\n",
    "        self.combine_heads = Dense(embed_dim)\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) # convert to another type use cast\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    # split heads method splits the inputs into multiple heads for parallel attention computation\n",
    "    def split_heads(self, x, batch_size): \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # the call method applies the setf attention mechanism and combine the heads\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)\n",
    "        key = self.key_dense(inputs)\n",
    "        value = self.value_dense(inputs)\n",
    "\n",
    "        # split heads func\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # attention func\n",
    "        attention = self.attention(query, key, value)\n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim))\n",
    "\n",
    "        output = self.combine_heads(concat_attention)\n",
    "        return output\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7124d60a-d12e-4f59-bc8a-76f5a82a463f",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The `MultiHeadSelfAttention` layer implements the multi-head self-attention mechanism, which allows the model to focus on different parts of the input sequence simultaneously. \n",
    "\n",
    "- The `attention parameter` computes the attention scores and weighted sum of the values. \n",
    "\n",
    "- The `split_heads` parameter splits the input into multiple heads for parallel attention computation. \n",
    "\n",
    "- The `call method` applies the self-attention mechanism and combines the heads. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc99a57-7c8f-492c-b6ae-5ae550d68c2a",
   "metadata": {},
   "source": [
    "### Step 3: Implement Transformer block \n",
    "\n",
    "Define the Transformer block. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "24dfae7a-87d3-4388-9f78-563ddb4d9a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class  TransformerBlock(Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate = 0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "\n",
    "        # Implement feed forward network layers\n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation = \"relu\"),\n",
    "            Dense(embed_dim)\n",
    "        ])\n",
    "\n",
    "        # Normalizatoin layers\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        # Dropout layers\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    # The call method applies the self-attention, followed by the feedforward network with residual connections and layer normalization.\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs +attn_output)\n",
    "\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training = training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8af8301-2383-4b89-869e-cffea717f49b",
   "metadata": {},
   "source": [
    "In the above code:\n",
    "\n",
    "- The `TransformerBlock layer` combines `multi-head self-attention` with a `feed-forward neural networ`k and `normalization layers`.  \n",
    "\n",
    "- `Dropout` is used to prevent overfitting. \n",
    "\n",
    "- The `call` method applies the `self-attention`, followed by the `feedforward network` with `residual connection`s and `layer normalization`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22f9e61-76cc-4f1a-99d4-a27c3f7da2cc",
   "metadata": {},
   "source": [
    "### Step 4: Implement Encoder Layer \n",
    "\n",
    "Define the Encoder layer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6ef6a9a8-2a6c-490f-acaf-796b231586e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate = 0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        \n",
    "        # Self attention layer\n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        \n",
    "        # feed forward network layer\n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation =\"relu\"),\n",
    "            Dense(embed_dim),\n",
    "        ])\n",
    "\n",
    "        # Normalization layers\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        \n",
    "        out1 = self.layernorm1(inputs + attn_output) # out1->input + attn_output\n",
    "        \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training)  \n",
    "        return self.layernorm2(out1 + ffn_output) # out1 + ffn_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ba7b3e-f5bd-421a-9804-7a2d1ac05366",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The `EncoderLayer` is similar to the `TransformerBlock` but is a reusable layer in the Transformer architecture. \n",
    "\n",
    "- It consists of a `MultiHeadSelfAttention mechanism` followed by a `feedforward neural network`. \n",
    "\n",
    "- Both sub-layers have residual connections around them, and layer normalization is applied to the output of each sub-layer. \n",
    "\n",
    "- The `call` method applies the self-attention, followed by the `feedforward network`, with `residual connections` and `layer normalization`. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2823e596-fcb3-4ebc-965d-1555a5649c26",
   "metadata": {},
   "source": [
    "### Step 5: Implement Transformer encoder \n",
    "\n",
    "Define the Transformer Encoder. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cf04fe8e-2668-44b0-bbb6-193b764aa363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 128)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout\n",
    "\n",
    "class MultiHeadSelfAttention(Layer):\n",
    "    def __init__(self, embed_dim, num_heads=8):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.projection_dim = embed_dim // num_heads\n",
    "        self.query_dense = Dense(embed_dim)\n",
    "        self.key_dense = Dense(embed_dim)\n",
    "        self.value_dense = Dense(embed_dim)\n",
    "        self.combine_heads = Dense(embed_dim)\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) # convert to another type use cast\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    # split heads method splits the inputs into multiple heads for parallel attention computation\n",
    "    def split_heads(self, x, batch_size): \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # the call method applies the setf attention mechanism and combine the heads\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)\n",
    "        key = self.key_dense(inputs)\n",
    "        value = self.value_dense(inputs)\n",
    "\n",
    "        # split heads func\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # attention func\n",
    "        attention, _ = self.attention(query, key, value)\n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim))\n",
    "\n",
    "        output = self.combine_heads(concat_attention)\n",
    "        return output\n",
    "    \n",
    "class  TransformerBlock(Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate = 0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "\n",
    "        # Implement feed forward network layers\n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation = \"relu\"),\n",
    "            Dense(embed_dim)\n",
    "        ])\n",
    "\n",
    "        # Normalizatoin layers\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        # Dropout layers\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    # The call method applies the self-attention, followed by the feedforward network with residual connections and layer normalization.\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs +attn_output)\n",
    "\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training = training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "class TransformerEncoder(Layer):\n",
    "    def __init__(self, num_layers, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.embed_dim = embed_dim\n",
    "        self.enc_layers = [TransformerBlock(embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)] \n",
    "        self.dropout = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = inputs\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training=training) \n",
    "        return x\n",
    "\n",
    "# sample usage\n",
    "embed_dim = 128\n",
    "num_heads = 8\n",
    "ff_dim = 512\n",
    "num_layers = 4\n",
    "\n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim)\n",
    "inputs = tf.random.uniform((1, 100, embed_dim))\n",
    "outputs = transformer_encoder(inputs, training=False) # Use keyword argument for 'training' \n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e107add-96b9-4f3a-9c89-007a3d88c500",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "The TransformerEncoder is composed of multiple TransformerBlock layers, implementing the encoding part of the Transformer architecture. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d666d157-6e8f-4cf1-aa24-f710c6f67573",
   "metadata": {},
   "source": [
    "### Step 6: Build and Compile the Transformer model \n",
    "\n",
    "Integrate the Transformer Encoder into a complete model for sequential data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1a9b22db-3ea0-4c8f-9a03-5ed3eaeed260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_68\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_68\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_496 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ transformer_encoder_19               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">793,088</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_497 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,801</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_64 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_496 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ transformer_encoder_19               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m793,088\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_8 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12800\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_497 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │          \u001b[38;5;34m12,801\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define necessary parameters\n",
    "\n",
    "embed_dim = 128\n",
    "num_heads = 8\n",
    "ff_dim = 512\n",
    "num_layers = 4\n",
    "\n",
    "# define transformer encoder\n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim)\n",
    "\n",
    "# Build the model\n",
    "input_shape = (x.shape[1], x.shape[2])\n",
    "inputs = tf.keras.Input(shape = input_shape)\n",
    "\n",
    "# project the inputs to the embed_dim\n",
    "x1 = tf.keras.layers.Dense(embed_dim)(inputs)\n",
    "encoder_outputs = transformer_encoder(x1)\n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs)\n",
    "outputs = tf.keras.layers.Dense(1)(flatten)\n",
    "\n",
    "# Create model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer = \"adam\",\n",
    "              loss = \"mse\"\n",
    "             )\n",
    "\n",
    "# summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe34b68-c077-4065-8401-02cc5134e0bd",
   "metadata": {},
   "source": [
    "### Step 7: Train the Transformer model \n",
    "\n",
    "Train the model on the prepared dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "89f2734a-d4ec-4c83-beed-81eef02403c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 166ms/step - loss: 11.5212\n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 167ms/step - loss: 0.2693\n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 175ms/step - loss: 0.1849\n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 169ms/step - loss: 0.1731\n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 164ms/step - loss: 0.1448\n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 166ms/step - loss: 0.1388\n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 168ms/step - loss: 0.1402\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 168ms/step - loss: 0.1218\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 167ms/step - loss: 0.2906\n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 169ms/step - loss: 0.0921\n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 168ms/step - loss: 0.0818\n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 171ms/step - loss: 0.1354\n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 169ms/step - loss: 0.0768\n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 168ms/step - loss: 0.1039\n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 169ms/step - loss: 0.0651\n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 173ms/step - loss: 0.0539\n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 168ms/step - loss: 0.0537\n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 169ms/step - loss: 0.0420\n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 169ms/step - loss: 0.0657\n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 169ms/step - loss: 0.0522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x24ae7bdcbd0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(x,y, epochs =20, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8072e58e-7233-45f7-846e-cbd95d0f95e9",
   "metadata": {},
   "source": [
    "The model is trained on the normalized stock price data for 20 epochs with a batch size of 32. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727195b2-3c20-4445-a35d-f03a7fe2bfd9",
   "metadata": {},
   "source": [
    "### Step 8: Evaluate and Make Predictions \n",
    "\n",
    "Evaluate the model's performance and make predictions on the dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "968c04a7-522e-4495-9adb-fa3b77a25715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(x)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "\n",
    "# plot the predictions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(data, label=\"True Data\")\n",
    "plt.plot(np.arange(time_step, time_step + len(predictions)), predictions, label='Predictions') \n",
    "plt.xlabel('Time') \n",
    "plt.ylabel('Stock Price') \n",
    "plt.legend() \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b588c7f0-410d-4858-843a-1051b26b0fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
